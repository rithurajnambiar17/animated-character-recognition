{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YKPgjfXiC_KH"
      },
      "outputs": [],
      "source": [
        "!unzip -q '/content/drive/MyDrive/dataset_2_animation_characters.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "IDy2LW-SbgL9"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import joblib\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1qAtmBmBJZ_m"
      },
      "outputs": [],
      "source": [
        "data_dir = pathlib.Path('/content/dataset_2_animation_characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H82WN2rBJnqI",
        "outputId": "6b70e0c8-fbbf-422a-e434-f240209d446c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14850"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#Calculating total number of images\n",
        "len(list(data_dir.glob('*/*.jpg')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WSLUovn2Ju7v"
      },
      "outputs": [],
      "source": [
        "#Initalizing required variables\n",
        "batch_size, img_height, img_width = 32, 180, 180"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6H6DFvCKJwG",
        "outputId": "ba4fccea-cb0d-417f-c036-b0d1d8aed4e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14850 files belonging to 15 classes.\n",
            "Using 11880 files for training.\n",
            "Found 14850 files belonging to 15 classes.\n",
            "Using 2970 files for validation.\n"
          ]
        }
      ],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=42,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=42,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3_YCgqQCMM2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01c0db84-214d-480d-a657-14d4fdb9b652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 0.99818456\n"
          ]
        }
      ],
      "source": [
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixel values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "u0DMjRNgKgYY"
      },
      "outputs": [],
      "source": [
        "num_classes = len(train_ds.class_names)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D())\n",
        "model.add(tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D())\n",
        "model.add(tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D())\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(num_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Q06u0U8PLnCp"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kvcPfJ4Mi-b",
        "outputId": "dfc17e29-8a11-41aa-959f-2428e7bac6ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "372/372 [==============================] - 29s 52ms/step - loss: 5.9626 - accuracy: 0.2274 - val_loss: 2.1501 - val_accuracy: 0.3232\n",
            "Epoch 2/10\n",
            "372/372 [==============================] - 20s 52ms/step - loss: 1.7112 - accuracy: 0.4531 - val_loss: 2.1178 - val_accuracy: 0.3953\n",
            "Epoch 3/10\n",
            "372/372 [==============================] - 19s 51ms/step - loss: 1.0366 - accuracy: 0.6715 - val_loss: 3.0102 - val_accuracy: 0.4219\n",
            "Epoch 4/10\n",
            "372/372 [==============================] - 19s 51ms/step - loss: 0.6176 - accuracy: 0.8112 - val_loss: 4.0791 - val_accuracy: 0.4067\n",
            "Epoch 5/10\n",
            "372/372 [==============================] - 19s 52ms/step - loss: 0.4108 - accuracy: 0.8775 - val_loss: 3.7565 - val_accuracy: 0.4471\n",
            "Epoch 6/10\n",
            "372/372 [==============================] - 19s 51ms/step - loss: 0.2976 - accuracy: 0.9129 - val_loss: 4.1201 - val_accuracy: 0.4394\n",
            "Epoch 7/10\n",
            "372/372 [==============================] - 19s 51ms/step - loss: 0.2872 - accuracy: 0.9180 - val_loss: 4.7403 - val_accuracy: 0.4303\n",
            "Epoch 8/10\n",
            "372/372 [==============================] - 19s 52ms/step - loss: 0.2334 - accuracy: 0.9356 - val_loss: 4.4653 - val_accuracy: 0.4370\n",
            "Epoch 9/10\n",
            "372/372 [==============================] - 19s 51ms/step - loss: 0.1385 - accuracy: 0.9581 - val_loss: 5.4724 - val_accuracy: 0.4636\n",
            "Epoch 10/10\n",
            "372/372 [==============================] - 19s 51ms/step - loss: 0.1424 - accuracy: 0.9621 - val_loss: 5.4218 - val_accuracy: 0.4407\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data = val_ds,\n",
        "  epochs = 10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "EvNn6V7bMkwI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16c61619-f198-490a-cb92-66e34ea61485"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ram://e0321fe3-fe63-4bcc-b358-d3c3f08c94c7/assets\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model.h5']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "joblib.dump(model, 'model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = '/content/dataset_2_animation_characters/chief_wiggum/pic_0002.jpg'\n",
        "img = tf.keras.utils.load_img(\n",
        "    img, target_size=(img_height, img_width)\n",
        ")"
      ],
      "metadata": {
        "id": "geZYFNjaYbkK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) # Create a batch"
      ],
      "metadata": {
        "id": "U_bj_zsCY7WC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "class_names = train_ds.class_names\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0GbLSNyY9oE",
        "outputId": "6943c06e-2814-437d-9ece-c6a18a95fe6a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This image most likely belongs to chief_wiggum with a 100.00 percent confidence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_img(model, img_path):\n",
        "  '''\n",
        "  Input : Model and Image Path\n",
        "  Output : Class Name and Confidence Score\n",
        "  '''\n",
        "  img = tf.keras.utils.load_img(\n",
        "      img_path, target_size = (180, 180)\n",
        "  )\n",
        "\n",
        "  class_names = ['abraham_grampa_simpson', 'apu_nahasapeemapetilon',\n",
        "                  'bart_simpson', 'charles_montgomery_burns', 'chief_wiggum',\n",
        "                  'edna_krabappel', 'homer_simpson', 'krusty_the_clown',\n",
        "                  'lenny_leonard', 'lisa_simpson', 'marge_simpson',\n",
        "                  'milhouse_van_houten', 'moe_szyslak', 'ned_flanders', 'principal_skinner']\n",
        "\n",
        "  img = tf.keras.utils.img_to_array(img)\n",
        "  img = tf.expand_dims(img, 0)\n",
        "\n",
        "  prediction = model.predict(img)\n",
        "  score = tf.nn.softmax(prediction[0])\n",
        "\n",
        "  return class_names[np.argmax(score)], 100 * np.max(score)\n",
        "  "
      ],
      "metadata": {
        "id": "YZgVCgIuZUt5"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgUrl = 'https://i.pinimg.com/564x/73/f5/9d/73f59debaae5e47af30f7e7e25558c16.jpg'\n",
        "\n",
        "imgPath = tf.keras.utils.get_file('Image', origin=imgUrl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cl8LAjqRasDT",
        "outputId": "1337f0fb-c22a-47c2-c5c1-bc33ee5389bc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://i.pinimg.com/564x/73/f5/9d/73f59debaae5e47af30f7e7e25558c16.jpg\n",
            "24576/24342 [==============================] - 0s 0us/step\n",
            "32768/24342 [========================================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_img(model, imgPath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARN-4lYpbMpD",
        "outputId": "da3eb087-9c80-4c08-f8ae-55c89751b3b7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('bart_simpson', 96.62958979606628)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}